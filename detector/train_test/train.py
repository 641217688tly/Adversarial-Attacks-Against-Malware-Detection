from detector.create_data.generate_dataset import get_dataset
from detector.resnet.resnet import resnet_34, resnet_18
from tensorboardX import SummaryWriter
import torch.nn as nn
import torch
import torch.utils.data

# 定义训练模型的函数
def train_model(model_path, epoch):
    """
    训练指定的模型。
    :param model_path: 保存模型的路径。
    :param epoch: 训练模型的迭代次数。
    :return: 训练好的模型。
    """
    # 获取训练数据的路径
    train_path = input("Please input the path of training data: ")
    if train_path[-1] != '/':
        train_path += '/'
    # 获取测试数据的路径
    test_path = input("Please input the path of test data: ")
    if test_path[-1] != '/':
        test_path += '/'

    # 初始化SummaryWriter，用于在TensorBoard上可视化训练过程
    writer = SummaryWriter(comment="ResNet")

    # 加载训练数据集
    dataset = get_dataset(train_path)
    # 获取训练数据的DataLoader
    train_loader = torch.utils.data.dataloader.DataLoader(dataset, batch_size=64)

    # 加载测试数据集
    dataset = get_dataset(test_path)
    # 获取测试数据的DataLoader
    test_loader = torch.utils.data.dataloader.DataLoader(dataset, batch_size=256)

    # 定义损失函数，这里使用交叉熵损失函数
    criterion = nn.CrossEntropyLoss().cuda()

    # 初始化模型，这里使用resnet_34
    model = resnet_18().cuda()

    # 为TensorBoard准备输入数据，用于可视化模型结构
    temp = torch.rand(32, 3, 224, 224).cuda()
    writer.add_graph(model, (temp,))

    # 定义优化器，这里使用Adam优化器
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)

    # 初始化最佳准确率
    best_accuracy = 0.0

    # 初始化步数，用于在TensorBoard上记录
    step = 0

    # 开始训练
    for i in range(epoch):
        print("epoch:", i)
        model.train()
        for j, data in enumerate(train_loader):
            x, y = data
            x = x.cuda()
            y = y.cuda()

            # 将数据转换为Variable，这是PyTorch中的一种数据结构，可以自动计算梯度
            x_var = torch.autograd.Variable(x)
            y_var = torch.autograd.Variable(y.long())

            # 前向传播，计算预测值
            prediction = model(x_var)

            # 计算损失
            loss = criterion(prediction, y_var)

            # 反向传播，更新权重
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            # 在TensorBoard上记录损失
            writer.add_scalar("Loss", loss, step)
            step += 1

        # 验证模型
        print('--------Validation--------')
        correct = torch.zeros(1).squeeze().cuda()
        total = torch.zeros(1).squeeze().cuda()
        model.eval()
        with torch.no_grad():
            for j, data in enumerate(test_loader):
                x, y = data
                x = x.cuda()
                y = y.cuda()

                # 前向传播，计算预测值
                output = model(x)

                # 计算准确率
                prediction = torch.argmax(output, 1)
                correct += (prediction == y.long()).sum().float()
                total += len(y)

            accuracy = (correct / total).cpu().item()
            # 在TensorBoard上记录准确率
            writer.add_scalar("Accuracy", accuracy, i)
            if accuracy > best_accuracy:
                # 保存最佳模型
                torch.save(model, "".join(model_path.split('.')[:-1]) + "_best.pth")
                best_accuracy = accuracy

    # 保存最终模型
    torch.save(model, model_path)
    # 关闭SummaryWriter
    writer.close()
