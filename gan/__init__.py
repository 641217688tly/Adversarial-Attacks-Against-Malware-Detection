import logging  # 引入日志处理模块，可以在运行时输出或记录调试和运行时信息。
import os
from enum import Enum
from typing import List, Tuple, Union  # 引入类型注解模块，提供了类型提示功能，有助于代码的可读性和减少bug。
from pathlib import Path  # 引入文件路径处理模块，提供了在不同操作系统下处理文件路径的能力。
import numpy as np
import tensorboardX  # 引入TensorboardX模块,它是一个用于可视化训练过程中的各种指标的工具,与PyTorch兼容
import torch
from torch import Tensor
import torch.nn as nn  # 从torch中引入nn模块,提供了构建神经网络的各种组件,如层、激活函数等
import torch.optim as optim  # 从torch.optim中引入优化器模块,提供了实现神经网络参数优化的算法
from torch.optim.optimizer import Optimizer  # 从torch.optim.optimizer中引入Optimizer类,它是所有优化器的基类
import torch.utils.data  # 从torch.utils.data中引入与数据加载和处理相关的模块和类
from torch.utils.data import Dataset, DataLoader, Subset  # 引入Dataset和DataLoader类,用于封装和加载数据集
from ._export_results import _export_results  # 从当前包中引入_export_results函数,用于导出训练结果
from ._log_tools import setup_logger, TrainingLogger  # 从当前包中引入setup_logger和TrainingLogger,用于设置和记录训练过程中的日志
from .detector import BlackBoxDetector  # 从当前包中引入BlackBoxDetector类,它代表一个黑盒检测器的模型
from .discriminator import Discriminator  # 从当前包中引入Discriminator类,它代表了MalGAN中的判别器
from .generator import Generator  # 从当前包中引入Generator类,它代表了MalGAN中的生成器

ListOrInt = Union[List[int], int]  # ListOrInt代表一个整数或一个整数列表。
PathOrStr = Union[str, Path]  # PathOrStr代表一个字符串或一个Path对象。
TensorTuple = Tuple[Tensor, Tensor]  # TensorTuple代表一个包含两个Tensor的元组。

IS_CUDA = torch.cuda.is_available()
if IS_CUDA:
    # 设置设备为第一个CUDA设备。
    device = torch.device('cuda:0')
    # 设置PyTorch的默认张量类型为CUDA浮点张量。
    torch.set_default_tensor_type(torch.cuda.FloatTensor)


class MalwareDataset(Dataset):  # 定义一个类，用于封装恶意软件数据集。
    def __init__(self, x: Union[np.ndarray, Tensor], y):
        # 调用父类的构造函数。
        super().__init__()
        # 如果输入x是NumPy数组，将其转换为PyTorch张量。
        if isinstance(x, np.ndarray):
            x = torch.from_numpy(x).float()
        # 将输入x和y赋值给类的属性。
        self.x = x
        self.y = y

    # 定义获取数据集中一个样本的方法。
    def __getitem__(self, index):
        # 返回指定索引位置的样本和标签。
        return self.x[index], self.y

    # 定义获取数据集大小的方法。
    def __len__(self):
        # 返回数据集中样本的数量。
        return self.x.shape[0]

    @property
    def num_features(self):
        # 返回数据集中每个样本的特征数量。
        return self.x.shape[1]


# 定义一个内部类，用于封装数据加载器或数据集。
class _DataGroup:  # pylint: disable=too-few-public-methods
    def __init__(self, train: MalwareDataset, valid: MalwareDataset, test: MalwareDataset):
        # 初始化训练、验证和测试数据集。
        self.train = train
        self.valid = valid
        self.test = test
        # 初始化标志，表示当前是否使用数据加载器。
        self.is_loaders = False

    # 定义构建数据加载器的方法。
    def build_loader(self, batch_size: int = 0):
        # 为训练数据集构建数据加载器，设置批次大小，打乱数据，开启内存预取。
        self.train = DataLoader(self.train, batch_size=batch_size, shuffle=False)
        # 如果验证数据集不为空，为验证数据集构建数据加载器。
        if self.valid:
            self.valid = DataLoader(self.valid, batch_size=batch_size)
        # 为测试数据集构建数据加载器。
        self.test = DataLoader(self.test, batch_size=batch_size)
        # 设置标志，表示当前使用的是数据加载器。
        self.is_loaders = True


# noinspection PyPep8Naming
class MalGAN(nn.Module):
    # 配置信息:
    MALWARE_BATCH_SIZE = 32  # 定义恶意软件的批处理大小，即每个批次处理的恶意软件样本数量
    VALIDATION_SPLIT = 0.2  # 设置验证集占总数据集的比例，用于模型评估和调参
    SAVED_MODEL_DIR = Path("saved_models")  # 设置保存训练好的模型的目录路径
    tensorboard = None  # 初始化tensorboard变量，用于可视化训练过程和结果

    class Label(Enum):
        Malware = 1  # 恶意软件标签
        Benign = 0  # 良性软件标签

    # 构造函数:
    def __init__(self, mal_data: 'MalwareDataset', ben_data: 'MalwareDataset', Z: int,
                 h_gen: Union[List[int], int], h_discrim: Union[List[int], int],
                 test_split: float = 0.2,
                 g_hidden: nn.Module = nn.LeakyReLU,
                 detector_type: 'BlackBoxDetector.Type' = 'BlackBoxDetector.Type.LogisticRegression'):
        r"""
        恶意软件生成对抗网络构造函数
        :param mal_data: 恶意软件训练数据集
        :param ben_data: 良性软件训练数据集
        :param Z: 噪声向量 z的维度
        :param h_gen: 生成器中隐藏层的宽度。如果只希望一个隐藏层，则可以只是一个整数
        :param h_discrim: 判别器中隐藏层的宽度。如果只希望一个隐藏层，则可以只是一个整数
        :param test_split: 用于测试的输入数据的比例
        :param g_hidden: 生成器和判别器中使用的激活函数
        :param detector_type: 黑盒检测器使用的学习算法
        """
        super().__init__()

        # ----------构造函数参数的有效性检查和初始化实例变量----------

        # 检查恶意软件和良性软件数据集的特征数量是否匹配
        if mal_data.num_features != ben_data.num_features:
            raise ValueError("Mismatch in the number of features between malware and benign data")
        # 确保Z是一个正整数
        if Z <= 0:
            raise ValueError("Z must be a positive integer")
        # 确保test_split在(0, 1)范围内
        if test_split <= 0. or test_split >= 1.:
            raise ValueError("test_split must be in the range (0,1)")

        self._M, self._Z = mal_data.num_features, Z  # 设置属性: _M是数据集的特征数量,_Z是噪声向量的维度

        # 格式化隐藏层大小并确保所有值都是有效的
        if isinstance(h_gen, int):
            h_gen = [h_gen]
        if isinstance(h_discrim, int):
            h_discrim = [h_discrim]
        self.d_discrim, self.d_gen = h_discrim, h_gen
        for h_size in [self.d_discrim, self.d_gen]:
            for w in h_size:
                if w <= 0:
                    raise ValueError("All hidden layer widths must be positive integers.")

        if not isinstance(g_hidden, nn.Module):
            g_hidden = g_hidden()
        self._g = g_hidden

        self._is_cuda = IS_CUDA  # _is_cuda标志表示当前是否使用GPU

        logging.debug("Constructing new MalGAN")  # "构建新的MalGAN"
        logging.debug("Malware Dimension (M): %d", self.M)  # "恶意软件维度(M): %d"
        logging.debug("Latent Dimension (Z): %d", self.Z)  # "潜在维度(Z): %d"
        logging.debug("Test Split Ratio: %.3f", test_split)  # "测试分割比: %.3f"
        logging.debug("Generator Hidden Layer Sizes: %s", h_gen)  # "生成器隐藏层大小: %s"
        logging.debug("Discriminator Hidden Layer Sizes: %s", h_discrim)  # "判别器隐藏层大小: %s"
        logging.debug("Blackbox Detector Type: %s", detector_type.name)  # "黑盒检测器类型: %s"
        logging.debug("Activation Type: %s", self._g.__class__.__name__)  # "激活类型: %s"

        self._bb = BlackBoxDetector(detector_type)
        self._gen = Generator(M=self.M, Z=self.Z, hidden_size=h_gen, g=self._g)
        self._discrim = Discriminator(M=self.M, hidden_size=h_discrim, g=self._g)

        # ----------数据集分割与处理----------

        def split_train_valid_test(dataset: Dataset, is_benign: bool):
            """
            将数据集划分为训练、验证和测试子集的辅助函数。
            :param dataset: 要划分的数据集。
            :param is_benign: 一个布尔值，指示数据集是否为良性样本。
            :return: 划分好的训练、验证和测试子集。
            """
            # 如果是良性样本，则不分配验证集，否则根据定义的验证集比例分配
            valid_len = 0 if is_benign else int(MalGAN.VALIDATION_SPLIT * len(dataset))
            # 根据定义的测试集比例分配测试集
            test_len = int(test_split * len(dataset))
            # 顺序必须是训练、验证、测试
            lengths = [len(dataset) - valid_len - test_len, valid_len, test_len]
            generator = torch.Generator(device='cuda')
            return _DataGroup(*torch.utils.data.random_split(dataset, lengths, generator=generator))

        # 在训练、测试和验证之间划分恶意和良性数据集，并构建数据加载器
        self._mal_data = split_train_valid_test(mal_data, is_benign=False)
        self._ben_data = split_train_valid_test(ben_data, is_benign=True)

        # 训练黑盒检测器(如果使用的是Resnet,由于我们的Resnet黑盒检测器已经训练好了,不需要进行这一步)
        self._fit_blackbox(self._mal_data.train, self._ben_data.train)

        # 构建恶意和良性数据的数据加载器
        self._mal_data.build_loader(MalGAN.MALWARE_BATCH_SIZE)
        ben_bs_frac = len(ben_data) / len(mal_data)
        self._ben_data.build_loader(int(ben_bs_frac * MalGAN.MALWARE_BATCH_SIZE))
        # 如果使用CUDA，则确保所有参数都已定义并传送到GPU
        if self._is_cuda: self.cuda()

    @property
    def M(self) -> int:
        return self._M

    @property
    def Z(self) -> int:
        return self._Z

    # ----------训练黑盒检测器----------
    def _fit_blackbox(self, mal_train: Subset, ben_train: Subset) -> None:
        """
        使用指定的恶意软件和良性软件训练集首先训练黑盒检测器。
        :param mal_train: 恶意软件训练数据集。
        :param ben_train: 良性软件训练数据集。
        """

        def extract_x(ds: Subset) -> Tensor:
            # 提取指定子集的特征
            # noinspection PyUnresolvedReferences
            x = ds.dataset.x[ds.indices]
            # 如果使用CUDA，将数据传送回CPU
            return x.cpu() if self._is_cuda else x

        # 提取恶意和良性训练数据的特征
        mal_x = extract_x(mal_train)
        ben_x = extract_x(ben_train)
        # 合并特征
        merged_x = torch.cat((mal_x, ben_x))

        # 创建标签，恶意为1，良性为0
        merged_y = torch.cat((torch.full((len(mal_train),), MalGAN.Label.Malware.value),
                              torch.full((len(ben_train),), MalGAN.Label.Benign.value)))
        # 开始训练黑盒检测器
        logging.debug("Starting training of blackbox detector of type \"%s\"", self._bb.type.name)
        self._bb.fit(merged_x, merged_y)  # 在此处训练黑盒检测器(如果选用Resnet,则会pass这一步,因为黑盒检测器已经训练好了)
        logging.debug("COMPLETED training of blackbox detector of type \"%s\"", self._bb.type.name)

    # ----------训练GAN模型(生成器+判别器)----------
    def fit(self, cyc_len: int, quiet_mode: bool = False) -> None:
        r"""
        训练模型指定数量的周期.使用验证损失最佳的周期作为最终模型。
        :param cyc_len: 训练模型的周期数。
        :param quiet_mode: 如果为True，则在此函数中不会打印到控制台
        """
        if cyc_len <= 0:
            raise ValueError("At least a single training cycle is required.")
        MalGAN.tensorboard = tensorboardX.SummaryWriter()

        # 使用Adam优化器初始化判别器和生成器的参数
        d_optimizer = optim.Adam(self._discrim.parameters(), lr=1e-5)
        g_optimizer = optim.Adam(self._gen.parameters(), lr=1e-4)

        if not quiet_mode:
            # 使用Adam优化器初始化判别器和生成器的参数
            names = ["Gen Train Loss", "Gen Valid Loss", "Discrim Train Loss", "Best?"]
            log = TrainingLogger(names, [20, 20, 20, 7])

        best_epoch, best_loss = None, np.inf
        for epoch_cnt in range(1, cyc_len + 1):
            # 进行一次训练
            train_l_g, train_l_d = self._fit_epoch(g_optimizer, d_optimizer)
            # 将训练损失写入tensorboard
            for block, loss in [("Generator", train_l_g), ("Discriminator", train_l_d)]:
                MalGAN.tensorboard.add_scalar('Train_%s_Loss' % block, loss, epoch_cnt)

            # noinspection PyTypeChecker
            valid_l_g = self._meas_loader_gen_loss(self._mal_data.valid)
            MalGAN.tensorboard.add_scalar('Validation_Generator_Loss', valid_l_g, epoch_cnt)
            flds = [train_l_g, valid_l_g, train_l_d, valid_l_g < best_loss]
            if flds[-1]:
                # 保存模型
                self._save(self._build_export_name(is_final=False))
                best_loss = valid_l_g
            if not quiet_mode:
                log.log(epoch_cnt, flds)  # 打印训练日志
        MalGAN.tensorboard.close()  # 关闭tensorboard

        # 加载最优模型并保存
        self.load(self._build_export_name(is_final=False))
        self._save(self._build_export_name(is_final=True))
        self._delete_old_backup(is_final=False)

    def _build_export_name(self, is_final: bool = True) -> str:
        """
        根据模型的参数构建模型的导出名称,用于在保存模型时命名模型

        :param is_final: 如果为True，则文件名是用于最终的模型（即不是训练时的模型）
        :return: 根据模型参数构建的模型名称
        """
        # 根据模型的各种参数和设置来构造名字
        name = ["malgan", "z=%d" % self.Z,
                "d-gen=%s" % str(self.d_gen).replace(" ", "_"),
                "d-disc=%s" % str(self.d_discrim).replace(" ", "_"),
                "bs=%d" % MalGAN.MALWARE_BATCH_SIZE,
                "bb=%s" % self._bb.type.name, "g=%s" % self._g.__class__.__name__,
                "final" if is_final else "tmp"]

        # Either add an epoch name or
        return MalGAN.SAVED_MODEL_DIR / "".join(["_".join(name).lower(), ".pth"])

    def _delete_old_backup(self, is_final: bool = True) -> None:
        """
        删除旧的模型备份。
        :param is_final: 如果为True，则文件名是用于最终的模型（即不是训练时的模型）
        """
        backup_name = self._build_export_name(is_final)
        try:
            os.remove(backup_name)
        except OSError:
            logging.warning("Error trying to delete model: %s", backup_name)

    # _fit_epoch函数执行单个训练周期（epoch）,通过优化生成器和判别器的参数来提升模型性能。
    def _fit_epoch(self, g_optim: Optimizer, d_optim: Optimizer) -> TensorTuple:
        r"""
        训练一个完整的周期
        g_optim: 生成器优化器,这里使用的是梯度下降的变种
        d_optim: 判别器优化器,这里使用的是梯度下降的变种
        return: 平均训练损失
        """

        tot_l_g = tot_l_d = 0  # tot_l_g 和 tot_l_d 分别存储生成器和判别器的总损失。
        num_batch = min(len(self._mal_data.train), len(self._ben_data.train))  # num_batch 是训练数据的批次数量，用于计算平均损失

        # 迭代恶意和良性数据的批次.zip函数将这两个数据集合并为一对对的批次。
        for (m, _), (b, _) in zip(self._mal_data.train, self._ben_data.train):
            # 如果启用了CUDA，将数据移到GPU上以加速计算。
            if self._is_cuda: m, b = m.cuda(), b.cuda()
            # 通过生成器前向传播恶意样本m，获取生成器的输出m_prime和g_theta。
            m_prime, g_theta = self._gen.forward(m)
            # 计算生成器损失并进行反向传播优化。
            l_g = self._calc_gen_loss(g_theta)
            g_optim.zero_grad()
            l_g.backward()
            g_optim.step()
            tot_l_g += l_g

            # 更新判别器
            for x in [m_prime, b]:
                l_d = self._calc_discrim_loss(x)
                d_optim.zero_grad()
                l_d.backward()
                d_optim.step()
                tot_l_d += l_d
            # 返回平均训练损失
        return (tot_l_g / num_batch).item(), (tot_l_d / num_batch).item()

    # _meas_loader_gen_loss 函数计算指定数据加载器上的生成器损失。
    def _meas_loader_gen_loss(self, loader: DataLoader) -> float:
        r""" 计算恶意软件数据集上的生成器损失 """
        # 初始化损失为0
        loss = 0
        # 遍历数据加载器中的所有批次
        for m, _ in loader:
            # 如果CUDA可用，将数据移动到GPU
            if self._is_cuda: m = m.cuda()
            # 前向传播，计算生成器的输出
            _, g_theta = self._gen.forward(m)
            # 计算生成器的损失并累加
            loss += self._calc_gen_loss(g_theta)
        # 计算平均损失并返回
        return (loss / len(loader)).item()

    def _calc_gen_loss(self, g_theta: Tensor) -> Tensor:
        r"""
        计算生成器的损失值L_{G}
        :param g_theta: :math:Gθg (m, z) = max (m, o) in Eq. (1)
        :return: Loss for the generator smoothed output.
        """
        # 计算判别器的输出
        d_theta = self._discrim.forward(g_theta)
        # 计算生成器损失
        return d_theta.log().mean()

    def _calc_discrim_loss(self, X: Tensor) -> Tensor:
        r"""
        计算判别器损失L_{D}
        :param X: Examples to calculate the loss over.  May be a mix of benign and malware samples.
        :return: Loss for the discriminator.
        """
        # 计算判别器的输出
        d_theta = self._discrim.forward(X)
        # 计算黑盒模型的预测
        y_hat = self._bb.predict(X)
        # 根据判别器的输出和黑盒模型的预测计算损失
        d = torch.where(y_hat == MalGAN.Label.Malware.value, d_theta, 1 - d_theta)
        # 返回损失
        return -d.log().mean()

    def measure_and_export_results(self) -> str:
        r"""
        Measure the test accuracy and provide results information
        :return: Results information as a comma separated string
        """
        # 计算验证集上的损失
        valid_loss = self._meas_loader_gen_loss(self._mal_data.valid)
        # 计算测试集上的损失
        test_loss = self._meas_loader_gen_loss(self._mal_data.test)
        # 在日志中记录验证集和测试集的损失
        logging.debug("Final Validation Loss: %.6f", valid_loss)
        logging.debug("Final Test Loss: %.6f", test_loss)

        num_mal_test = 0
        y_mal_orig, m_prime_arr, bits_changed = [], [], []
        # 迭代测试数据集
        for m, _ in self._mal_data.test:
            # 预测原始恶意软件的标签
            y_mal_orig.append(self._bb.predict(m.cpu()))
            if self._is_cuda:
                m = m.cuda()
            num_mal_test += m.shape[0]

            # 通过生成器生成修改后的恶意软件样本
            m_prime, _ = self._gen.forward(m)
            # 存储修改后的样本
            m_prime_arr.append(m_prime.cpu() if self._is_cuda else m_prime)

            # 计算修改了多少个比特
            m_diff = m_prime - m
            bits_changed.append(torch.sum(m_diff.cpu(), dim=1))

            # 检查是否有从1翻转到0的比特,这是不允许的(因为这可能导致Malware所使用的关键API被禁用)
            msg = "Malware signature changed to 0 which is not allowed"
            assert torch.sum(m_diff < -0.1) == 0, msg
        avg_changed_bits = torch.cat(bits_changed).mean()
        # 记录平均改变了多少个比特
        logging.debug("Avg. Malware Bits Changed Changed: %2f", avg_changed_bits)

        # BB预测生成器修改前的恶意软件
        y_mal_orig = torch.cat(y_mal_orig)

        # 构建预测用的X张量
        ben_test_arr = [x.cpu() if self._is_cuda else x for x, _ in self._ben_data.test]
        x = torch.cat(m_prime_arr + ben_test_arr)
        y_actual = torch.cat((torch.full((num_mal_test,), MalGAN.Label.Malware.value),
                              torch.full((len(x) - num_mal_test,), MalGAN.Label.Benign.value)))

        # BB预测生成器修改后的恶意软件
        y_hat_post = self._bb.predict(x)
        if self._is_cuda:
            y_mal_orig, y_hat_post, y_actual = y_mal_orig.cpu(), y_hat_post.cpu(), y_actual.cpu()
        # 使用BB模型预测概率
        y_prob = self._bb._model.predict_proba(x)  # 这里访问了受保护的成员
        y_prob = y_prob[:, MalGAN.Label.Malware.value]
        # 导出结果
        return _export_results(self, valid_loss, test_loss, avg_changed_bits, y_actual,
                               y_mal_orig, y_prob, y_hat_post)

    def _save(self, file_path: PathOrStr) -> None:
        r"""
        Export the specified model to disk.  The function creates any files needed on the path.
        All exported models will be relative to \p EXPORT_DIR class object.

        :param file_path: Path to export the model.
        """
        # 如果file_path是字符串，转换为Path对象
        if isinstance(file_path, str):
            file_path = Path(file_path)
        # 创建需要的所有目录
        file_path.parent.mkdir(parents=True, exist_ok=True)
        # 保存模型的状态字典
        torch.save(self.state_dict(), str(file_path))

    def forward(self, x: Tensor) -> TensorTuple:  # pylint: disable=arguments-differ
        r"""
        Passes a malware tensor and augments it to make it more undetectable by

        :param x: Malware binary tensor
        :return: :math:`m'` and :math:`g_{\theta}` respectively
        """
        # 将输入x传递给生成器，并返回结果
        return self._gen.forward(x)

    def load(self, filename: PathOrStr) -> None:
        r"""
        Load a MalGAN object from disk.  MalGAN's \p EXPORT_DIR is prepended to the specified
        filename.

        :param filename: Path to the exported torch file
        """
        # 如果filename是Path对象，转换为字符串
        if isinstance(filename, Path):
            filename = str(filename)
        # 加载模型状态
        self.load_state_dict(torch.load(filename))
        # 设置为评估模式
        self.eval()
        # 根据GAN Hacks建议，在评估模式下启用dropout可以提升性能
        for m in self._gen.modules():
            if m.__class__.__name__.startswith('Dropout'):
                m.train()

    @staticmethod
    def _print_memory_usage() -> None:
        """
        Helper function to print the allocated tensor memory.  This is used to debug out of memory
        GPU errors.
        """
        import gc
        import operator as op
        from functools import reduce
        # 遍历所有Python对象
        for obj in gc.get_objects():
            try:
                # 检查对象是否为PyTorch张量或包含PyTorch张量的对象
                if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
                    if len(obj.size()) > 0:  # 检查张量是否非空
                        # 计算张量总大小
                        obj_tot_size = reduce(op.mul, obj.size())
                    else:
                        obj_tot_size = "NA"
                    # 打印张量大小、类型和形状
                    print(obj_tot_size, type(obj), obj.size())
            except:
                pass
